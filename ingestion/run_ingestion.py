import os
import xml.etree.ElementTree as ET
import json
import re
from tqdm import tqdm

# ================= è·¯å¾„é…ç½® =================
SCRIPT_DIR = os.path.dirname(os.path.abspath(__file__))
PROJECT_ROOT = os.path.dirname(SCRIPT_DIR)
XML_FILENAME = "simplewiki-latest-pages-articles.xml"
RAW_FILE_PATH = os.path.join(PROJECT_ROOT, "data", "raw", XML_FILENAME)
OUTPUT_FILE = os.path.join(PROJECT_ROOT, "data", "intermediate", "corpus.jsonl")


# ===========================================

def normalize_id(title):
    if not title: return ""
    return title.strip().replace(" ", "_")


def clean_and_extract_links(wiki_text):
    if not wiki_text: return "", []
    out_links = []
    # åŒ¹é… [[Target|Label]] æˆ– [[Target]]
    pattern = re.compile(r'\[\[([^|\]]+)(?:\|([^\]]+))?\]\]')

    def replace_func(match):
        target = match.group(1)
        label = match.group(2) if match.group(2) else target
        if ":" not in target:
            out_links.append(normalize_id(target))
        return label

    text_step1 = pattern.sub(replace_func, wiki_text)
    return text_step1, out_links


def strip_tag_name(t):
    """
    è¾…åŠ©å‡½æ•°ï¼šå»æ‰ {http://...} è¿™ç§å‰ç¼€
    """
    if '}' in t:
        return t.split('}', 1)[1]
    return t


def process_xml():
    print(f"ğŸ“‚ è¯»å–æ–‡ä»¶: {RAW_FILE_PATH}")
    if not os.path.exists(RAW_FILE_PATH):
        print("âŒ æ–‡ä»¶ä¸å­˜åœ¨ï¼è¯·æ£€æŸ¥è·¯å¾„ã€‚")
        return

    print(f"ğŸš€ å¼€å§‹å¤„ç† XML...")
    os.makedirs(os.path.dirname(OUTPUT_FILE), exist_ok=True)

    count = 0

    with open(OUTPUT_FILE, "w", encoding="utf-8") as f_out:
        # ä½¿ç”¨ iterparse æµå¼è¯»å–
        context = ET.iterparse(RAW_FILE_PATH, events=("end",))

        for event, elem in context:
            # è·å–å»é™¤äº†å‘½åç©ºé—´çš„æ ‡ç­¾å
            tag = strip_tag_name(elem.tag)

            if tag == "page":
                title = None
                text = None

                # éå†å­èŠ‚ç‚¹æŸ¥æ‰¾ title å’Œ text
                for child in elem:
                    child_tag = strip_tag_name(child.tag)
                    if child_tag == "title":
                        title = child.text
                    elif child_tag == "revision":
                        for rev_child in child:
                            if strip_tag_name(rev_child.tag) == "text":
                                text = rev_child.text
                                break

                if title and text:
                    # è¿‡æ»¤ç‰¹æ®Šé¡µé¢
                    if ":" not in title:
                        doc_id = normalize_id(title)
                        clean_text, links = clean_and_extract_links(text)

                        doc = {
                            "id": doc_id,
                            "text": clean_text,
                            "out_links": links
                        }
                        f_out.write(json.dumps(doc) + "\n")
                        count += 1

                        if count % 1000 == 0:
                            print(f"âœ… å·²ç”Ÿæˆ {count} æ¡æ•°æ®...", end="\r")

                # --- ä¿®å¤ç‚¹ï¼šæ ‡å‡†åº“çš„å†…å­˜æ¸…ç†æ–¹å¼ ---
                # åªéœ€ clear å³å¯ï¼Œä¸è¦ç”¨ getprevious
                elem.clear()

            # è¿™é‡Œä¸éœ€è¦ else æ‰“å°äº†ï¼Œé¿å…åˆ·å±

    print(f"\nâœ¨ å¤„ç†å®Œæˆï¼å…±ç”Ÿæˆ {count} æ¡æ•°æ®ã€‚")
    print(f"ğŸ“ ç»“æœä¿å­˜åœ¨: {OUTPUT_FILE}")


if __name__ == "__main__":
    process_xml()