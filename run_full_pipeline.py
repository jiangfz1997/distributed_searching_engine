import subprocess
import time
import sys
import os

# === âš™ï¸ é…ç½®åŒºåŸŸ ===
# å¹¶å‘å·¥äººæ•°é‡ (æ ¹æ®ä½ çš„ CPU æ ¸æ•°è°ƒæ•´)
NUM_MAPPERS = 4
NUM_PR_WORKERS = 4

# è¶…æ—¶è®¾ç½® (ç§’)
TIMEOUT_MAPPER = 600  # ç­‰å¾… Mapper å®Œæˆçš„æœ€å¤§æ—¶é—´
TIMEOUT_PR = 600  # ç­‰å¾… PageRank å®Œæˆçš„æœ€å¤§æ—¶é—´


def log(msg):
    print(f"\nğŸš€ [PIPELINE] {msg}")


def run_cmd(args, description, ignore_error=False):
    """æ‰§è¡Œ Shell å‘½ä»¤å¹¶æ‰“å°è€—æ—¶"""
    print(f"   ğŸ‘‰ Executing: {description}...")
    start_time = time.time()

    try:
        # Windows ä¸‹ shell=True é€šå¸¸æ›´ç¨³å®š
        use_shell = True if os.name == 'nt' else False

        # å°†åˆ—è¡¨è½¬ä¸ºå­—ç¬¦ä¸²å‘½ä»¤ (æ–¹ä¾¿ Windows å¤„ç†)
        if isinstance(args, list):
            cmd_str = " ".join(args)
        else:
            cmd_str = args

        subprocess.run(cmd_str, check=True, shell=use_shell)

    except subprocess.CalledProcessError as e:
        if ignore_error:
            print(f"   âš ï¸ Warning: {description} failed (Ignored).")
        else:
            print(f"   âŒ Error in step: {description}")
            print(f"   Command: {cmd_str}")
            sys.exit(1)

    duration = time.time() - start_time
    print(f"   âœ… Done ({duration:.2f}s).")


def wait_for_service(service_name, check_cmd, timeout=60):
    """ç­‰å¾…æŸä¸ªæœåŠ¡å‡†å¤‡å°±ç»ª (é€šè¿‡åå¤æ‰§è¡Œ check_cmd)"""
    print(f"   â³ Waiting for {service_name} to be ready...")
    start = time.time()
    while time.time() - start < timeout:
        try:
            subprocess.run(check_cmd, shell=True, check=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)
            print(f"   âœ… {service_name} is ready.")
            return
        except:
            time.sleep(2)
            print(".", end="", flush=True)
    print(f"\n   âŒ Timeout waiting for {service_name}.")
    sys.exit(1)


def main():
    total_start = time.time()
    print("=" * 60)
    print("   ğŸ” INDUSTRIAL SEARCH ENGINE - AUTOMATION PIPELINE")
    print("=" * 60)

    # ---------------------------------------------------------
    # 1. ç¯å¢ƒæ¸…ç†ä¸åˆå§‹åŒ–
    # ---------------------------------------------------------
    log("Step 1: Environment Cleanup & Init")
    run_cmd("docker-compose down --remove-orphans", "Stopping old containers")

    # é‡å»ºé•œåƒ (ç¡®ä¿ NLTK, psycopg2 ç­‰ä¾èµ–æœ€æ–°)
    log("Step 1.1: Building Images (ensure dependencies)")
    run_cmd("docker-compose build", "Building Docker Images")

    # å¯åŠ¨åŸºç¡€è®¾æ–½
    run_cmd("docker-compose up -d redis postgres", "Starting Infrastructure")

    # ç­‰å¾… Postgres å°±ç»ª
    wait_for_service("Postgres", "docker-compose exec postgres pg_isready -U admin")

    # === å…³é”®ï¼šæ¸…ç©ºæ—§æ•°æ® (Drop Tables) ===
    # è¿™ä¸€æ­¥æ˜¯ä¸ºäº†ç¡®ä¿è¡¨ç»“æ„æ›´æ–°ä¸º JSONB
    drop_sql = "DROP TABLE IF EXISTS inverted_index; DROP TABLE IF EXISTS pagerank; DROP TABLE IF EXISTS metadata;"
    run_cmd(f'docker-compose exec postgres psql -U admin -d search_engine -c "{drop_sql}"', "Dropping old tables")

    # æ¸…ç©º Redis
    run_cmd("docker-compose exec redis redis-cli FLUSHALL", "Flushing Redis")

    # åˆå§‹åŒ–æ–°è¡¨
    run_cmd("docker-compose run --rm compute-node python compute/db_utils.py", "Initializing DB Tables (JSONB)")

    # ---------------------------------------------------------
    # 2. æ•°æ®æ¸…æ´— (Ingestion)
    # ---------------------------------------------------------
    log("Step 2: Data Ingestion (XML -> JSONL)")
    # å‡è®¾ä½ çš„ ingestion è„šæœ¬åœ¨ src/run_ingestion.py
    run_cmd("docker-compose run --rm compute-node python src/run_ingestion.py", "Running Ingestion")

    # ---------------------------------------------------------
    # 3. å€’æ’ç´¢å¼• (Indexing)
    # ---------------------------------------------------------
    log("Step 3: Distributed Indexing")

    # 3.1 æ¸…ç†ä¸­é—´æ–‡ä»¶
    run_cmd("docker-compose run --rm compute-node rm -rf /app/data/temp_shuffle/*", "Cleaning temp files")

    # 3.2 å‘å¸ƒä»»åŠ¡
    run_cmd("docker-compose run --rm compute-node python compute/indexing/controller.py --phase map",
            "Publishing Map Tasks")

    # 3.3 å¯åŠ¨ Mapper é›†ç¾¤
    print(f"   ğŸš€ Launching {NUM_MAPPERS} Mappers...")
    # ä½¿ç”¨ scale å¯åŠ¨å¤šä¸ª mapper
    # æ³¨æ„ï¼šmapper å¿…é¡»æœ‰ idle è‡ªåŠ¨é€€å‡ºæœºåˆ¶ï¼Œå¦åˆ™è¿™é‡Œä¼šä¸€ç›´è¿è¡Œ
    # ä¸ºäº†è„šæœ¬èƒ½ç»§ç»­ï¼Œæˆ‘ä»¬ä½¿ç”¨ detached mode (-d)
    subprocess.run(f"docker-compose up -d --scale compute-node={NUM_MAPPERS}", shell=True)
    # è¿™é‡Œçš„ compute-node é»˜è®¤ command æ˜¯ tail -fï¼Œæˆ‘ä»¬éœ€è¦æ‰‹åŠ¨æŒ‡å®š command è¿è¡Œ mapper
    # ä¿®æ­£ï¼šç›´æ¥ç”¨ run -d å¤šæ¬¡
    for i in range(NUM_MAPPERS):
        subprocess.run("docker-compose run -d compute-node python compute/indexing/mapper.py", shell=True)

    # 3.4 ç­‰å¾… Mapper å®Œæˆ
    print("   â³ Waiting for Mappers to finish (Monitor via Docker PS)...")
    wait_start = time.time()
    while True:
        # æ£€æŸ¥æ˜¯å¦è¿˜æœ‰ mapper.py è¿›ç¨‹åœ¨è·‘
        res = subprocess.run('docker ps -q --filter "ancestor=search-compute:v1"', shell=True, capture_output=True,
                             text=True)
        # æ³¨æ„ï¼šè¿™é‡Œæœ‰ç‚¹ trickyï¼Œå› ä¸º controller å’Œ reducer ä¹Ÿæ˜¯è¿™ä¸ªé•œåƒã€‚
        # æœ€å¥½æ˜¯æ£€æŸ¥æ—¥å¿—æˆ–è¿›ç¨‹åˆ—è¡¨ã€‚
        # ç®€å•æ–¹æ¡ˆï¼šæŸ¥çœ‹ Redis é˜Ÿåˆ—é•¿åº¦
        res_q = subprocess.run('docker-compose exec redis redis-cli LLEN queue:indexing:mapper', shell=True,
                               capture_output=True, text=True)
        queue_len = int(res_q.stdout.strip())

        # è¿˜éœ€è¦æ£€æŸ¥ processing é˜Ÿåˆ—
        res_p = subprocess.run('docker-compose exec redis redis-cli LLEN queue:indexing:mapper:processing', shell=True,
                               capture_output=True, text=True)
        proc_len = int(res_p.stdout.strip())

        if queue_len == 0 and proc_len == 0:
            print("\n   âœ… All Map tasks processed.")
            # ç»™ä¸€ç‚¹æ—¶é—´è®© Mapper å†™ç›˜é€€å‡º
            time.sleep(5)
            break

        if time.time() - wait_start > TIMEOUT_MAPPER:
            print("   âŒ Mapper Timeout!")
            sys.exit(1)

        print(f"      Remaining Tasks: {queue_len} | Processing: {proc_len}   ", end='\r')
        time.sleep(2)

    # 3.5 è¿è¡Œ Reducer (å…¥åº“)
    run_cmd("docker-compose run --rm compute-node python compute/indexing/reducer.py",
            "Running Reducer (Insert to Postgres)")

    # ---------------------------------------------------------
    # 4. å›¾è®¡ç®— (PageRank)
    # ---------------------------------------------------------
    log("Step 4: PageRank Calculation")

    # 4.1 æå–è¾¹
    run_cmd("docker-compose run --rm compute-node python compute/pagerank/extract_edges.py", "Extracting Edges")

    # 4.2 åŠ è½½å›¾
    run_cmd("docker-compose run --rm compute-node python compute/pagerank/graph_loader.py", "Loading Graph to Redis")

    # 4.3 å¯åŠ¨é›†ç¾¤
    print(f"   ğŸš€ Starting PR Controller + {NUM_PR_WORKERS} Workers...")
    subprocess.run(f"docker-compose up -d pr-controller --scale pr-worker={NUM_PR_WORKERS}", shell=True)

    # 4.4 ç­‰å¾…æ”¶æ•› (ç›‘æ§ Controller é€€å‡º)
    print("   â³ Waiting for PageRank convergence...")
    wait_start = time.time()
    while True:
        # æ£€æŸ¥ pr-controller å®¹å™¨æ˜¯å¦è¿˜åœ¨è¿è¡Œ
        res = subprocess.run('docker ps -q -f "name=pr-controller"', shell=True, capture_output=True, text=True)
        if not res.stdout.strip():
            print("\n   âœ… PageRank Controller finished.")
            break

        if time.time() - wait_start > TIMEOUT_PR:
            print("   âŒ PageRank Timeout!")
            sys.exit(1)

        time.sleep(5)
        print("      Calculation in progress...", end='\r')

    # 4.5 å¯¼å‡º PR ç»“æœ (è‡ªåŠ¨å¯¼å‡ºå¯èƒ½å·²åœ¨ Controller åšè¿‡ï¼Œä½†è¿™é‡Œå†è·‘ä¸€æ¬¡ç¡®ä¿ä¸‡ä¸€)
    run_cmd("docker-compose run --rm compute-node python compute/pagerank/export_pagerank_sql.py",
            "Exporting PR to Postgres")

    # åœæ­¢ PR é›†ç¾¤
    run_cmd("docker-compose stop pr-controller pr-worker", "Stopping PR Cluster")

    # ---------------------------------------------------------
    # 5. å…ƒæ•°æ® (Metadata)
    # ---------------------------------------------------------
    log("Step 5: Metadata Export")
    run_cmd("docker-compose run --rm compute-node python compute/export_metadata.py",
            "Exporting Text & Length to Postgres")

    # ---------------------------------------------------------
    # 6. æœåŠ¡ä¸Šçº¿
    # ---------------------------------------------------------
    log("Step 6: Deploying Search Engine")
    run_cmd("docker-compose up -d backend", "Starting Backend Service")

    # ---------------------------------------------------------
    # å®Œæˆ
    # ---------------------------------------------------------
    total_time = time.time() - total_start
    print("\n" + "=" * 60)
    print(f"ğŸ‰ PIPELINE COMPLETED in {total_time / 60:.2f} minutes!")
    print("ğŸ‘‰ Search API: http://localhost:8000/docs")
    print("=" * 60)


if __name__ == "__main__":
    main()